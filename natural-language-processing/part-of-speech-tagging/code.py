# -*- coding: utf-8 -*-
"""code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1euYsL7C-3IWvMIUsSJZeByrdjKAYF1m8
"""

import nltk
from sklearn.model_selection import train_test_split
from tqdm.auto import tqdm
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import numpy as np
import seaborn as sns
nltk.download('treebank')
nltk.download('universal_tagset')

class GetFormattedDataset:
    def __init__(self):
        dataset = nltk.corpus.treebank.tagged_sents(tagset='universal')
        train_set, test_set = train_test_split(dataset, test_size=0.15, random_state=42)
        train_set, dev_set = train_test_split(dataset, test_size=0.15, random_state=42)
        self.dataset = dict()
        self.dataset["x_train"] = [[d[0].lower() for d in data] for data in train_set]
        self.dataset["y_train"] = [[d[1] for d in data] for data in train_set]
        self.dataset["x_dev"] = [[d[0].lower() for d in data] for data in dev_set]
        self.dataset["y_dev"] = [[d[1] for d in data] for data in dev_set]
        self.dataset["x_test"] = [[d[0].lower() for d in data] for data in test_set]
        self.dataset["y_test"] = [[d[1] for d in data] for data in test_set]
        self.vocab = set([word for sentence in self.dataset["x_train"] for word in sentence])
        self.tags = set([tag for sentence in self.dataset["y_train"] for tag in sentence])

data_dict = GetFormattedDataset()

class Trainer:
    def __init__(self, data_dict: GetFormattedDataset, units=64, rnn="SimpleRNN") -> None:
        self.data_dict = data_dict
        self.rnn = rnn
        self.tokenizer = Tokenizer(num_words=15000, oov_token="[UNK]")
        self.tokenizer.fit_on_texts(data_dict.dataset["x_train"])
        self.tokenized_x_train = pad_sequences(self.tokenizer.texts_to_sequences(data_dict.dataset["x_train"]), maxlen=100, padding="post")
        self.tokenized_x_dev = pad_sequences(self.tokenizer.texts_to_sequences(data_dict.dataset["x_dev"]), maxlen=100, padding="post")
        self.tokenized_x_test = pad_sequences(self.tokenizer.texts_to_sequences(data_dict.dataset["x_test"]), maxlen=100, padding="post")

        self.tag_tokenizer = Tokenizer()
        self.tag_tokenizer.fit_on_texts(data_dict.dataset["y_train"])
        self.tokenized_y_train = to_categorical(pad_sequences(self.tag_tokenizer.texts_to_sequences(data_dict.dataset["y_train"]), maxlen=100, padding="post"), num_classes = len(self.data_dict.tags) + 1)
        self.tokenized_y_dev = to_categorical(pad_sequences(self.tag_tokenizer.texts_to_sequences(data_dict.dataset["y_dev"]), maxlen=100, padding="post"), num_classes = len(self.data_dict.tags) + 1)
        self.tokenized_y_test = to_categorical(pad_sequences(self.tag_tokenizer.texts_to_sequences(data_dict.dataset["y_test"]), maxlen=100, padding="post"), num_classes = len(self.data_dict.tags) + 1)

        self.model = self.build_model(units)
        self.history = None

    def build_model(self, units):
        rnn_map = {
            "SimpleRNN": tf.keras.layers.SimpleRNN(units, return_sequences=True),
            "GRU": tf.keras.layers.GRU(units, return_sequences=True),
            "LSTM": tf.keras.layers.LSTM(units, return_sequences=True),
        }
        model = tf.keras.Sequential([
            tf.keras.layers.Embedding(input_dim=15000, output_dim=32, input_length=100),
            rnn_map[self.rnn],
            tf.keras.layers.TimeDistributed(
                tf.keras.layers.Dense(len(self.data_dict.tags) + 1,
                                      activation='softmax')
            )
        ])
        model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        return model

    def train(self, batch_size=128, epochs=50):
        early_stopping = tf.keras.callbacks.EarlyStopping(
            monitor='val_loss',
            verbose=1,
            patience=5,
            mode='min',
            restore_best_weights=True
        )
        self.history = self.model.fit(
            self.tokenized_x_train, self.tokenized_y_train,
            batch_size=batch_size,
            epochs=epochs,
            verbose=1,
            validation_data=(self.tokenized_x_dev, self.tokenized_y_dev),
            callbacks=[early_stopping],
        )

# Train using RNN
rnnTrainer = Trainer(data_dict, units=64)
rnnTrainer.train(batch_size=64, epochs=40)


# Plot Figures
fig = plt.figure(figsize=(12, 4))
metrics = ['loss', 'accuracy']
for n, metric in enumerate(metrics):
    plt.subplot(1, 2, n+1)
    plt.plot(rnnTrainer.history.epoch, rnnTrainer.history.history[metric], label='Train')
    plt.plot(rnnTrainer.history.epoch, rnnTrainer.history.history[f"val_{metric}"], linestyle="--", label='Validation')
    plt.xlabel('Epoch')
    plt.ylabel(metric)
    plt.title(metric)
plt.legend()
plt.show()




[test_loss, test_acc] = rnnTrainer.model.evaluate(rnnTrainer.tokenized_x_test, rnnTrainer.tokenized_y_test)
print("Test Loss:", test_loss, "Test Accuracy (w/ padding):", test_acc)

def flatten(t):
    return [item for sublist in t for item in sublist]

test_preds = np.argmax(rnnTrainer.model.predict(rnnTrainer.tokenized_x_test), axis=-1)
test_preds = flatten([test_preds[i][:len(data_dict.dataset["x_test"][i])] for i in range(len(test_preds))])
y_test = np.argmax(rnnTrainer.tokenized_y_test, axis=-1)
y_test = flatten([y_test[i][:len(data_dict.dataset["y_test"][i])] for i in range(len(y_test))])
cm = confusion_matrix(y_test, test_preds)
plt.figure(figsize=(7, 5))
ax = sns.heatmap(cm, annot=True, fmt="d")
bottom, top = ax.get_ylim()
ax.set_ylim(bottom + 0.5, top - 0.5)
plt.title('Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()
print("Test Accuracy (w/o padding):", accuracy_score(y_test, test_preds))

# Traing using GRU
gruTrainer = Trainer(data_dict, units=64, rnn="GRU")
gruTrainer.train(batch_size=64, epochs=40)




# Plot Figures
fig = plt.figure(figsize=(12, 4))
metrics = ['loss', 'accuracy']
for n, metric in enumerate(metrics):
    plt.subplot(1, 2, n+1)
    plt.plot(gruTrainer.history.epoch, gruTrainer.history.history[metric], label='Train')
    plt.plot(gruTrainer.history.epoch, gruTrainer.history.history[f"val_{metric}"], linestyle="--", label='Validation')
    plt.xlabel('Epoch')
    plt.ylabel(metric)
    plt.title(metric)
plt.legend()
plt.show()




[test_loss, test_acc] = gruTrainer.model.evaluate(gruTrainer.tokenized_x_test, gruTrainer.tokenized_y_test)
print("Test Loss:", test_loss, "Test Accuracy (w/ padding):", test_acc)

def flatten(t):
    return [item for sublist in t for item in sublist]

test_preds = np.argmax(gruTrainer.model.predict(gruTrainer.tokenized_x_test), axis=-1)
test_preds = flatten([test_preds[i][:len(data_dict.dataset["x_test"][i])] for i in range(len(test_preds))])
y_test = np.argmax(gruTrainer.tokenized_y_test, axis=-1)
y_test = flatten([y_test[i][:len(data_dict.dataset["y_test"][i])] for i in range(len(y_test))])
cm = confusion_matrix(y_test, test_preds)
plt.figure(figsize=(7, 5))
ax = sns.heatmap(cm, annot=True, fmt="d")
bottom, top = ax.get_ylim()
ax.set_ylim(bottom + 0.5, top - 0.5)
plt.title('Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()
print("Test Accuracy (w/o padding):", accuracy_score(y_test, test_preds))

# Train using LSTM
lstmTrainer = Trainer(data_dict, units=64, rnn="LSTM")
lstmTrainer.train(batch_size=64, epochs=40)



# Plot Figures
fig = plt.figure(figsize=(12, 4))
metrics = ['loss', 'accuracy']
for n, metric in enumerate(metrics):
    plt.subplot(1, 2, n+1)
    plt.plot(lstmTrainer.history.epoch, lstmTrainer.history.history[metric], label='Train')
    plt.plot(lstmTrainer.history.epoch, lstmTrainer.history.history[f"val_{metric}"], linestyle="--", label='Validation')
    plt.xlabel('Epoch')
    plt.ylabel(metric)
    plt.title(metric)
plt.legend()
plt.show()




[test_loss, test_acc] = lstmTrainer.model.evaluate(lstmTrainer.tokenized_x_test, lstmTrainer.tokenized_y_test)
print("Test Loss:", test_loss, "Test Accuracy (w/ padding):", test_acc)

def flatten(t):
    return [item for sublist in t for item in sublist]

test_preds = np.argmax(lstmTrainer.model.predict(lstmTrainer.tokenized_x_test), axis=-1)
test_preds = flatten([test_preds[i][:len(data_dict.dataset["x_test"][i])] for i in range(len(test_preds))])
y_test = np.argmax(lstmTrainer.tokenized_y_test, axis=-1)
y_test = flatten([y_test[i][:len(data_dict.dataset["y_test"][i])] for i in range(len(y_test))])
cm = confusion_matrix(y_test, test_preds)
plt.figure(figsize=(7, 5))
ax = sns.heatmap(cm, annot=True, fmt="d")
bottom, top = ax.get_ylim()
ax.set_ylim(bottom + 0.5, top - 0.5)
plt.title('Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()
print("Test Accuracy (w/o padding):", accuracy_score(y_test, test_preds))
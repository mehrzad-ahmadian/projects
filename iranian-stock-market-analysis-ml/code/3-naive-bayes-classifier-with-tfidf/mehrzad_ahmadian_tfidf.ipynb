{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "e_6YMxQzRrV5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "hJPQYV5dcN-s"
      },
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "\n",
        "\n",
        "# trainDataset = 'taaghche'\n",
        "\n",
        "trainDataset = 'stocks'\n",
        "trainDatasetFile = 'sentiment'\n",
        "# trainDatasetFile = 'signal'\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "!mkdir dataset\n",
        "!wget https://ahmadian.me/final-dataset/taaghche.csv -O dataset/taaghche.csv\n",
        "\n",
        "!wget https://ahmadian.me/final-dataset/stocks-test-sentiment.csv -O dataset/stocks-test-sentiment.csv\n",
        "!wget https://ahmadian.me/final-dataset/stocks-test-signal.csv -O dataset/stocks-test-signal.csv\n",
        "!wget https://ahmadian.me/final-dataset/stocks-train-sentiment.csv -O dataset/stocks-train-sentiment.csv\n",
        "!wget https://ahmadian.me/final-dataset/stocks-train-signal.csv -O dataset/stocks-train-signal.csv"
      ],
      "metadata": {
        "id": "pZ1l0EvXcT3H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10a84aca-d7e1-490c-e451-f1e79c953521"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-05 19:10:23--  https://ahmadian.me/final-dataset/taaghche.csv\n",
            "Resolving ahmadian.me (ahmadian.me)... 157.90.0.201\n",
            "Connecting to ahmadian.me (ahmadian.me)|157.90.0.201|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 22056405 (21M) [text/csv]\n",
            "Saving to: ‘dataset/taaghche.csv’\n",
            "\n",
            "dataset/taaghche.cs 100%[===================>]  21.03M  13.4MB/s    in 1.6s    \n",
            "\n",
            "2022-07-05 19:10:25 (13.4 MB/s) - ‘dataset/taaghche.csv’ saved [22056405/22056405]\n",
            "\n",
            "--2022-07-05 19:10:26--  https://ahmadian.me/final-dataset/stocks-test-sentiment.csv\n",
            "Resolving ahmadian.me (ahmadian.me)... 157.90.0.201\n",
            "Connecting to ahmadian.me (ahmadian.me)|157.90.0.201|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 287771 (281K) [text/csv]\n",
            "Saving to: ‘dataset/stocks-test-sentiment.csv’\n",
            "\n",
            "dataset/stocks-test 100%[===================>] 281.03K   635KB/s    in 0.4s    \n",
            "\n",
            "2022-07-05 19:10:26 (635 KB/s) - ‘dataset/stocks-test-sentiment.csv’ saved [287771/287771]\n",
            "\n",
            "--2022-07-05 19:10:27--  https://ahmadian.me/final-dataset/stocks-test-signal.csv\n",
            "Resolving ahmadian.me (ahmadian.me)... 157.90.0.201\n",
            "Connecting to ahmadian.me (ahmadian.me)|157.90.0.201|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 358777 (350K) [text/csv]\n",
            "Saving to: ‘dataset/stocks-test-signal.csv’\n",
            "\n",
            "dataset/stocks-test 100%[===================>] 350.37K   785KB/s    in 0.4s    \n",
            "\n",
            "2022-07-05 19:10:27 (785 KB/s) - ‘dataset/stocks-test-signal.csv’ saved [358777/358777]\n",
            "\n",
            "--2022-07-05 19:10:28--  https://ahmadian.me/final-dataset/stocks-train-sentiment.csv\n",
            "Resolving ahmadian.me (ahmadian.me)... 157.90.0.201\n",
            "Connecting to ahmadian.me (ahmadian.me)|157.90.0.201|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 849212 (829K) [text/csv]\n",
            "Saving to: ‘dataset/stocks-train-sentiment.csv’\n",
            "\n",
            "dataset/stocks-trai 100%[===================>] 829.31K  1.45MB/s    in 0.6s    \n",
            "\n",
            "2022-07-05 19:10:29 (1.45 MB/s) - ‘dataset/stocks-train-sentiment.csv’ saved [849212/849212]\n",
            "\n",
            "--2022-07-05 19:10:29--  https://ahmadian.me/final-dataset/stocks-train-signal.csv\n",
            "Resolving ahmadian.me (ahmadian.me)... 157.90.0.201\n",
            "Connecting to ahmadian.me (ahmadian.me)|157.90.0.201|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 778206 (760K) [text/csv]\n",
            "Saving to: ‘dataset/stocks-train-signal.csv’\n",
            "\n",
            "dataset/stocks-trai 100%[===================>] 759.97K  1.32MB/s    in 0.6s    \n",
            "\n",
            "2022-07-05 19:10:30 (1.32 MB/s) - ‘dataset/stocks-train-signal.csv’ saved [778206/778206]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "D3mvfHxVcN-i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "853663c2-5274-4917-c66d-ec0cf1086087"
      },
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "!pip install -qU hazm\n",
        "!pip install -qU clean-text[gpl]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 17.1 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 30 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 40 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 51 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 61 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 81 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 92 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 266 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 276 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 286 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 296 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 307 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 316 kB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 233 kB 35.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 35.6 MB/s \n",
            "\u001b[?25h  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 175 kB 5.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 235 kB 48.7 MB/s \n",
            "\u001b[?25h  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "gfDmZQbucN-j"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import hazm\n",
        "from cleantext import clean\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import copy\n",
        "import collections\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "Q8AbmTadcN-k"
      },
      "cell_type": "code",
      "source": [
        "if trainDataset == 'taaghche':\n",
        "    data = pd.read_csv('dataset/taaghche.csv', encoding='utf-8')\n",
        "    data = data[['comment', 'rate']]\n",
        "\n",
        "\n",
        "    # handle some conflicts with the dataset structure\n",
        "    # you can find a reliable solution, for the sake of the simplicity\n",
        "    # I just remove these bad combinations!\n",
        "    data['rate'] = data['rate'].apply(lambda r: r if r < 6 else None)\n",
        "\n",
        "    data = data.dropna(subset=['rate'])\n",
        "    data = data.dropna(subset=['comment'])\n",
        "    data = data.drop_duplicates(subset=['comment'], keep='first')\n",
        "    data = data.reset_index(drop=True)\n",
        "\n",
        "\n",
        "    # calculate the length of comments based on their words\n",
        "    data['comment_len_by_words'] = data['comment'].apply(lambda t: len(hazm.word_tokenize(t)))\n",
        "\n",
        "\n",
        "    def rate_to_label(rate, threshold=3.0):\n",
        "        if rate <= threshold:\n",
        "            return 'negative'\n",
        "        else:\n",
        "            return 'positive'\n",
        "\n",
        "\n",
        "    data['label'] = data['rate'].apply(lambda t: rate_to_label(t, 3.0))\n",
        "    data.head()\n",
        "elif trainDataset == 'stocks':\n",
        "    if trainDatasetFile == 'sentiment':\n",
        "        data = pd.read_csv('dataset/stocks-train-sentiment.csv', encoding='utf-8')\n",
        "    else:\n",
        "        data = pd.read_csv('dataset/stocks-train-signal.csv', encoding='utf-8')\n",
        "\n",
        "\n",
        "    data = data[['message', 'sentiment_label']]\n",
        "    data = data.rename(columns={\"message\": \"comment\", \"sentiment_label\": \"label_id\"})\n",
        "\n",
        "\n",
        "    # data = data[data['label_id'] != 0]\n",
        "\n",
        "    data['label'] = data['label_id']\n",
        "    data = data.replace({'label': {0: 'neutral', 1: 'positive', 2: 'negative'}})\n",
        "\n",
        "\n",
        "    # calculate the length of comments based on their words\n",
        "    data['comment_len_by_words'] = data['comment'].apply(lambda t: len(hazm.word_tokenize(t)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if trainDatasetFile == 'sentiment':\n",
        "        dataTest = pd.read_csv('dataset/stocks-test-sentiment.csv', encoding='utf-8')\n",
        "    else:\n",
        "        dataTest = pd.read_csv('dataset/stocks-test-signal.csv', encoding='utf-8')\n",
        "\n",
        "    dataTest = dataTest[['message', 'sentiment_label']]\n",
        "    dataTest = dataTest.rename(columns={\"message\": \"comment\", \"sentiment_label\": \"label_id\"})\n",
        "\n",
        "\n",
        "    # dataTest = dataTest[dataTest['label_id'] != 0]\n",
        "\n",
        "    dataTest['label'] = dataTest['label_id']\n",
        "    dataTest = dataTest.replace({'label': {0: 'neutral', 1: 'positive', 2: 'negative'}})\n",
        "\n",
        "\n",
        "    # calculate the length of comments based on their words\n",
        "    dataTest['comment_len_by_words'] = dataTest['comment'].apply(lambda t: len(hazm.word_tokenize(t)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "labels = list(sorted(data['label'].unique()))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "enjRqEwfcN-m"
      },
      "cell_type": "code",
      "source": [
        "def data_gl_than(data, less_than=100.0, greater_than=0.0, col='comment_len_by_words'):\n",
        "    data_length = data[col].values\n",
        "\n",
        "    data_glt = sum([1 for length in data_length if greater_than < length <= less_than])\n",
        "\n",
        "    data_glt_rate = (data_glt / len(data_length)) * 100\n",
        "\n",
        "    print(f'Texts with word length of greater than {greater_than} and less than {less_than} includes {data_glt_rate:.2f}% of the whole!')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "pLNF1SrWcN-o"
      },
      "cell_type": "code",
      "source": [
        "def cleanhtml(raw_html):\n",
        "    cleanr = re.compile('<.*?>')\n",
        "    cleantext = re.sub(cleanr, '', raw_html)\n",
        "    return cleantext\n",
        "\n",
        "\n",
        "def cleaning(text):\n",
        "    text = text.strip()\n",
        "    \n",
        "    # regular cleaning\n",
        "    text = clean(text,\n",
        "        fix_unicode=True,\n",
        "        to_ascii=False,\n",
        "        lower=True,\n",
        "        no_line_breaks=True,\n",
        "        no_urls=True,\n",
        "        no_emails=True,\n",
        "        no_phone_numbers=True,\n",
        "        no_numbers=False,\n",
        "        no_digits=False,\n",
        "        no_currency_symbols=True,\n",
        "        no_punct=False,\n",
        "        replace_with_url=\"\",\n",
        "        replace_with_email=\"\",\n",
        "        replace_with_phone_number=\"\",\n",
        "        replace_with_number=\"\",\n",
        "        replace_with_digit=\"0\",\n",
        "        replace_with_currency_symbol=\"\",\n",
        "    )\n",
        "\n",
        "    # cleaning htmls\n",
        "    text = cleanhtml(text)\n",
        "    \n",
        "    # normalizing\n",
        "    normalizer = hazm.Normalizer()\n",
        "    text = normalizer.normalize(text)\n",
        "    \n",
        "    # removing wierd patterns\n",
        "    wierd_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u'\\U00010000-\\U0010ffff'\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u2640-\\u2642\"\n",
        "        u\"\\u2600-\\u2B55\"\n",
        "        u\"\\u23cf\"\n",
        "        u\"\\u23e9\"\n",
        "        u\"\\u231a\"\n",
        "        u\"\\u3030\"\n",
        "        u\"\\ufe0f\"\n",
        "        u\"\\u2069\"\n",
        "        u\"\\u2066\"\n",
        "        # u\"\\u200c\"\n",
        "        u\"\\u2068\"\n",
        "        u\"\\u2067\"\n",
        "        \"]+\", flags=re.UNICODE)\n",
        "    \n",
        "    text = wierd_pattern.sub(r'', text)\n",
        "    \n",
        "    # removing extra spaces, hashtags\n",
        "    text = re.sub(\"#\", \"\", text)\n",
        "    text = re.sub(\"\\s+\", \" \", text)\n",
        "    \n",
        "    return text"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2O5RdY5ucN-m",
        "outputId": "09783521-0645-425d-c349-0d95939cdab4"
      },
      "cell_type": "code",
      "source": [
        "data_gl_than(data, 256, 3)\n",
        "\n",
        "\n",
        "minlim, maxlim = 3, 256\n",
        "\n",
        "\n",
        "# remove comments with the length of fewer than three words\n",
        "data['comment_len_by_words'] = data['comment_len_by_words'].apply(lambda len_t: len_t if minlim < len_t <= maxlim else None)\n",
        "data = data.dropna(subset=['comment_len_by_words'])\n",
        "data = data.reset_index(drop=True)\n",
        "\n",
        "\n",
        "# cleaning comments\n",
        "data['cleaned_comment'] = data['comment'].apply(cleaning)\n",
        "\n",
        "\n",
        "# calculate the length of comments based on their words\n",
        "data['cleaned_comment_len_by_words'] = data['cleaned_comment'].apply(lambda t: len(hazm.word_tokenize(t)))\n",
        "\n",
        "# remove comments with the length of fewer than three words\n",
        "data['cleaned_comment_len_by_words'] = data['cleaned_comment_len_by_words'].apply(lambda len_t: len_t if minlim < len_t <= maxlim else len_t)\n",
        "data = data.dropna(subset=['cleaned_comment_len_by_words'])\n",
        "data = data.reset_index(drop=True)\n",
        "\n",
        "data.head()\n",
        "\n",
        "\n",
        "data = data[['cleaned_comment', 'label']]\n",
        "data.columns = ['comment', 'label']\n",
        "data.head()\n",
        "\n",
        "\n",
        "if trainDataset == 'stocks':\n",
        "    data_gl_than(dataTest, 256, 3)\n",
        "\n",
        "\n",
        "    minlim, maxlim = 3, 256\n",
        "\n",
        "\n",
        "    # remove comments with the length of fewer than three words\n",
        "    dataTest['comment_len_by_words'] = dataTest['comment_len_by_words'].apply(lambda len_t: len_t if minlim < len_t <= maxlim else None)\n",
        "    dataTest = dataTest.dropna(subset=['comment_len_by_words'])\n",
        "    dataTest = dataTest.reset_index(drop=True)\n",
        "\n",
        "\n",
        "    # cleaning comments\n",
        "    dataTest['cleaned_comment'] = dataTest['comment'].apply(cleaning)\n",
        "\n",
        "\n",
        "    # calculate the length of comments based on their words\n",
        "    dataTest['cleaned_comment_len_by_words'] = dataTest['cleaned_comment'].apply(lambda t: len(hazm.word_tokenize(t)))\n",
        "\n",
        "    # remove comments with the length of fewer than three words\n",
        "    dataTest['cleaned_comment_len_by_words'] = dataTest['cleaned_comment_len_by_words'].apply(lambda len_t: len_t if minlim < len_t <= maxlim else len_t)\n",
        "    dataTest = dataTest.dropna(subset=['cleaned_comment_len_by_words'])\n",
        "    dataTest = dataTest.reset_index(drop=True)\n",
        "\n",
        "    dataTest.head()\n",
        "\n",
        "\n",
        "    dataTest = dataTest[['cleaned_comment', 'label']]\n",
        "    dataTest.columns = ['comment', 'label']\n",
        "    dataTest.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texts with word length of greater than 3 and less than 256 includes 99.04% of the whole!\n",
            "Texts with word length of greater than 3 and less than 256 includes 94.37% of the whole!\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "leHOJ5nPcN-q"
      },
      "cell_type": "code",
      "source": [
        "new_data = data\n",
        "\n",
        "if trainDataset == 'stocks':\n",
        "    new_data_test = dataTest"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "IYkQy7AtcN-q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "595ad482-9ded-4412-fe80-8997ebdf5a32"
      },
      "cell_type": "code",
      "source": [
        "# split data to train valid test\n",
        "new_data['label_id'] = new_data['label'].apply(lambda t: labels.index(t))\n",
        "\n",
        "if trainDataset == 'stocks':\n",
        "    new_data_test['label_id'] = new_data_test['label'].apply(lambda t: labels.index(t))\n",
        "    valid, test = train_test_split(new_data_test, test_size=0.1, random_state=1, stratify=new_data_test['label'])\n",
        "    train = data\n",
        "else:\n",
        "    train, test = train_test_split(new_data, test_size=0.1, random_state=1, stratify=new_data['label'])\n",
        "    train, valid = train_test_split(train, test_size=0.1, random_state=1, stratify=train['label'])\n",
        "\n",
        "train = train.reset_index(drop=True)\n",
        "valid = valid.reset_index(drop=True)\n",
        "test = test.reset_index(drop=True)\n",
        "\n",
        "x_train, y_train = train['comment'].values.tolist(), train['label_id'].values.tolist()\n",
        "x_valid, y_valid = valid['comment'].values.tolist(), valid['label_id'].values.tolist()\n",
        "x_test, y_test = test['comment'].values.tolist(), test['label_id'].values.tolist()\n",
        "\n",
        "print(train.shape)\n",
        "print(valid.shape)\n",
        "print(test.shape)\n",
        "\n",
        "label_list = ['negative', 'positive', 'neutral']"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(206, 3)\n",
            "(60, 3)\n",
            "(7, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "modifyFeatures = {\n",
        "    'افزایش': 10,\n",
        "    'رشد': 10,\n",
        "    'بهبود': 10,\n",
        "    'مثبت': 10,\n",
        "    'صف خرید': 10,\n",
        "    'خرید': 10,\n",
        "    \n",
        "    'کاهش': 10,\n",
        "    'افت': 10,\n",
        "    'حاصل نکرده': 10,\n",
        "    'منفی': 10,\n",
        "    'صف فروش': 10,\n",
        "    'ریزش': 10,\n",
        "}\n",
        "\n",
        "train = pd.concat([train, valid, test])\n",
        "\n",
        "commentsData = train['comment'].to_numpy()\n",
        "yData = [label_list.index(label) for label in train['label'].values]\n",
        "\n",
        "# Building a TF IDF matrix out of the corpus of reviews\n",
        "\n",
        "td = TfidfVectorizer(max_features = 4500)\n",
        "commentsData = td.fit_transform(commentsData).toarray()\n",
        "\n",
        "features = td.get_feature_names()\n",
        "\n",
        "for key in modifyFeatures:\n",
        "    if key in features:\n",
        "        idx = features.index(key)\n",
        "        for comment in commentsData:\n",
        "          comment[idx] *= modifyFeatures[key]\n",
        "\n",
        "# Splitting into training & test subsets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, yData = train_test_split(commentsData, yData, test_size = 0.4,\n",
        "                                                    random_state = 0, shuffle=False)\n",
        "\n",
        "# Training the classifier & predicting on test data\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "#  generate yhat\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Classification metrics\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "classification_report = classification_report(yData, y_pred)\n",
        "\n",
        "print('\\n Accuracy: ', accuracy_score(yData, y_pred))\n",
        "print('\\nClassification Report')\n",
        "print('======================================================')\n",
        "print('\\n', classification_report)\n",
        "print()\n",
        "\n",
        "\n",
        "\n",
        "cm = metrics.confusion_matrix(yData, y_pred)\n",
        "fig, ax = plt.subplots()\n",
        "sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, \n",
        "            cbar=False)\n",
        "ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=label_list, \n",
        "       yticklabels=label_list, title=\"Confusion matrix\")\n",
        "plt.yticks(rotation=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "id": "qs7j6hatiJt-",
        "outputId": "ba737188-6af6-4026-d3c4-6d7255d40177"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Accuracy:  0.42727272727272725\n",
            "\n",
            "Classification Report\n",
            "======================================================\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        48\n",
            "           1       0.43      0.97      0.59        39\n",
            "           2       0.43      0.39      0.41        23\n",
            "\n",
            "    accuracy                           0.43       110\n",
            "   macro avg       0.29      0.46      0.33       110\n",
            "weighted avg       0.24      0.43      0.30       110\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.5, 1.5, 2.5]), <a list of 3 Text major ticklabel objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "mehrzad_ahmadian_tfidf.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
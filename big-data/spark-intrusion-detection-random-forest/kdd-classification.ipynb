{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.types import * \n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "import time\n",
    "\n",
    "# Create SparkSession\n",
    "spark = SparkSession.builder.appName(\"Classification\").master(\"local[4]\").config(\"spark.executor.cores\", 4).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define correct schema\n",
    "data_schema = [StructField(\"duration\", IntegerType(), True),\n",
    "StructField(\"protocol_type\", StringType(), True),\n",
    "StructField(\"service\", StringType(), True),\n",
    "StructField(\"flag\", StringType(), True),\n",
    "StructField(\"src_bytes\", IntegerType(), True),\n",
    "StructField(\"dst_bytes\", IntegerType(), True),\n",
    "StructField(\"land\", IntegerType(), True),\n",
    "StructField(\"wrong_fragment\", IntegerType(), True),\n",
    "StructField(\"urgent\", IntegerType(), True),\n",
    "StructField(\"hot\", IntegerType(), True),\n",
    "StructField(\"num_failed_logins\", IntegerType(), True),\n",
    "StructField(\"logged_in\", IntegerType(), True),\n",
    "StructField(\"num_compromised\", IntegerType(), True),\n",
    "StructField(\"root_shell\", IntegerType(), True),\n",
    "StructField(\"su_attempted\", IntegerType(), True),\n",
    "StructField(\"num_root\", IntegerType(), True),\n",
    "StructField(\"num_file_creations\", IntegerType(), True),\n",
    "StructField(\"num_shells\", IntegerType(), True),\n",
    "StructField(\"num_access_files\", IntegerType(), True),\n",
    "StructField(\"num_outbound_cmds\", IntegerType(), True),\n",
    "StructField(\"is_host_login\", IntegerType(), True),\n",
    "StructField(\"is_guest_login\", IntegerType(), True),\n",
    "StructField(\"count\", IntegerType(), True),\n",
    "StructField(\"srv_count\", IntegerType(), True),\n",
    "StructField(\"serror_rate\", DoubleType(), True),\n",
    "StructField(\"srv_serror_rate\", DoubleType(), True),\n",
    "StructField(\"rerror_rate\", DoubleType(), True),\n",
    "StructField(\"srv_rerror_rate\", DoubleType(), True),\n",
    "StructField(\"same_srv_rate\", DoubleType(), True),\n",
    "StructField(\"diff_srv_rate\", DoubleType(), True),\n",
    "StructField(\"srv_diff_host_rate\", DoubleType(), True),\n",
    "StructField(\"dst_host_count\", IntegerType(), True),\n",
    "StructField(\"dst_host_srv_count\", IntegerType(), True),\n",
    "StructField(\"dst_host_same_srv_rate\", DoubleType(), True),\n",
    "StructField(\"dst_host_diff_srv_rate\", DoubleType(), True),\n",
    "StructField(\"dst_host_same_src_port_rate\", DoubleType(), True),\n",
    "StructField(\"dst_host_srv_diff_host_rate\", DoubleType(), True),\n",
    "StructField(\"dst_host_serror_rate\", DoubleType(), True),\n",
    "StructField(\"dst_host_srv_serror_rate\", DoubleType(), True),\n",
    "StructField(\"dst_host_rerror_rate\", DoubleType(), True),\n",
    "StructField(\"dst_host_srv_rerror_rate\", DoubleType(), True),\n",
    "StructField(\"category\", StringType(), True)]\n",
    "\n",
    "final_struc = StructType(fields=data_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train and test data\n",
    "path =\"data/\"\n",
    "train_df = spark.read.csv(path+'kddcup.data',schema=final_struc)\n",
    "test_df = spark.read.csv(path+'corrected',schema=final_struc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all attack classes to 4 main attack classes\n",
    "train_df = train_df.withColumn('category', \n",
    "    when(train_df.category == 'back.', 'dos')\n",
    "    .when(train_df.category == 'buffer_overflow.', 'u2r')\n",
    "    .when(train_df.category == 'ftp_write.', 'r2l')\n",
    "    .when(train_df.category == 'guess_passwd.', 'r2l')\n",
    "    .when(train_df.category == 'imap.', 'r2l')\n",
    "    .when(train_df.category == 'ipsweep.', 'probe')\n",
    "    .when(train_df.category == 'land.', 'dos')\n",
    "    .when(train_df.category == 'loadmodule.', 'u2r')\n",
    "    .when(train_df.category == 'multihop.', 'r2l')\n",
    "    .when(train_df.category == 'neptune.', 'dos')\n",
    "    .when(train_df.category == 'nmap.', 'probe')\n",
    "    .when(train_df.category == 'perl.', 'u2r')\n",
    "    .when(train_df.category == 'phf.', 'r2l')\n",
    "    .when(train_df.category == 'pod.', 'dos')\n",
    "    .when(train_df.category == 'portsweep.', 'probe')\n",
    "    .when(train_df.category == 'rootkit.', 'u2r')\n",
    "    .when(train_df.category == 'satan.', 'probe')\n",
    "    .when(train_df.category == 'smurf.', 'dos')\n",
    "    .when(train_df.category == 'spy.', 'r2l')\n",
    "    .when(train_df.category == 'teardrop.', 'dos')\n",
    "    .when(train_df.category == 'warezclient.', 'r2l')\n",
    "    .when(train_df.category == 'warezmaster.', 'r2l')\n",
    "    .otherwise('normal')\n",
    " )\n",
    "counts = train_df.groupBy(\"category\").count()\n",
    "counts.orderBy(desc(\"count\")).show(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all attack classes to 4 main attack classes\n",
    "test_df = test_df.withColumn('category', \n",
    "    when(test_df.category == 'back.', 'dos')\n",
    "    .when(test_df.category == 'buffer_overflow.', 'u2r')\n",
    "    .when(test_df.category == 'ftp_write.', 'r2l')\n",
    "    .when(test_df.category == 'guess_passwd.', 'r2l')\n",
    "    .when(test_df.category == 'imap.', 'r2l')\n",
    "    .when(test_df.category == 'ipsweep.', 'probe')\n",
    "    .when(test_df.category == 'land.', 'dos')\n",
    "    .when(test_df.category == 'loadmodule.', 'u2r')\n",
    "    .when(test_df.category == 'multihop.', 'r2l')\n",
    "    .when(test_df.category == 'neptune.', 'dos')\n",
    "    .when(test_df.category == 'nmap.', 'probe')\n",
    "    .when(test_df.category == 'perl.', 'u2r')\n",
    "    .when(test_df.category == 'phf.', 'r2l')\n",
    "    .when(test_df.category == 'pod.', 'dos')\n",
    "    .when(test_df.category == 'portsweep.', 'probe')\n",
    "    .when(test_df.category == 'rootkit.', 'u2r')\n",
    "    .when(test_df.category == 'satan.', 'probe')\n",
    "    .when(test_df.category == 'smurf.', 'dos')\n",
    "    .when(test_df.category == 'spy.', 'r2l')\n",
    "    .when(test_df.category == 'teardrop.', 'dos')\n",
    "    .when(test_df.category == 'warezclient.', 'r2l')\n",
    "    .when(test_df.category == 'warezmaster.', 'r2l')\n",
    "    .otherwise('normal')\n",
    " )\n",
    "counts = test_df.groupBy(\"category\").count()\n",
    "counts.orderBy(desc(\"count\")).show(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = train_df.columns[0:-1]\n",
    "input_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change label (class variable) to string type to prep for reindexing\n",
    "# Pyspark is expecting a zero indexed integer for the label column. \n",
    "# Just in case our data is not in that format... we will treat it by using the StringIndexer built in method\n",
    "dependent_var = 'category'\n",
    "\n",
    "train_renamed = train_df.withColumn(\"label_str\", train_df[dependent_var].cast(StringType())) #Rename and change to string type\n",
    "train_indexer = StringIndexer(inputCol=\"label_str\", outputCol=\"label\") #Pyspark is expecting the this naming convention \n",
    "train_indexed = train_indexer.fit(train_renamed).transform(train_renamed)\n",
    "\n",
    "test_renamed = test_df.withColumn(\"label_str\", test_df[dependent_var].cast(StringType())) #Rename and change to string type\n",
    "test_indexer = StringIndexer(inputCol=\"label_str\", outputCol=\"label\") #Pyspark is expecting the this naming convention \n",
    "test_indexed = test_indexer.fit(test_renamed).transform(test_renamed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all string type data in the input column list to numeric\n",
    "# Otherwise the Algorithm will not be able to process it\n",
    "\n",
    "# Also we will use these lists later on\n",
    "train_numeric_inputs = []\n",
    "train_string_inputs = []\n",
    "for column in input_columns:\n",
    "    # First identify the string vars in your input column list\n",
    "    if str(train_indexed.schema[column].dataType) == 'StringType':\n",
    "        # Set up your String Indexer function\n",
    "        train_indexer = StringIndexer(inputCol=column, outputCol=column+\"_num\") \n",
    "        # Then call on the train_indexer you created here\n",
    "        train_indexed = train_indexer.fit(train_indexed).transform(train_indexed)\n",
    "        # Rename the column to a new name so you can disinguish it from the original\n",
    "        new_col_name = column+\"_num\"\n",
    "        # Add the new column name to the string inputs list\n",
    "        train_string_inputs.append(new_col_name)\n",
    "    else:\n",
    "        # If no change was needed, take no action \n",
    "        # And add the numeric var to the num list\n",
    "        train_numeric_inputs.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all string type data in the input column list to numeric\n",
    "# Otherwise the Algorithm will not be able to process it\n",
    "\n",
    "test_numeric_inputs = []\n",
    "test_string_inputs = []\n",
    "for column in input_columns:\n",
    "    # First identify the string vars in your input column list\n",
    "    if str(test_indexed.schema[column].dataType) == 'StringType':\n",
    "        # Set up your String Indexer function\n",
    "        test_indexer = StringIndexer(inputCol=column, outputCol=column+\"_num2\") \n",
    "        # Then call on the test_indexer you created here\n",
    "        test_indexed = test_indexer.fit(test_indexed).transform(test_indexed)\n",
    "        # Rename the column to a new name so you can disinguish it from the original\n",
    "        new_col_name = column+\"_num2\"\n",
    "        # Add the new column name to the string inputs list\n",
    "        test_string_inputs.append(new_col_name)\n",
    "    else:\n",
    "        # If no change was needed, take no action \n",
    "        # And add the numeric var to the num list\n",
    "        test_numeric_inputs.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indexed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indexed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we correct for negative values that may have been found above, \n",
    "# We need to vectorize our df\n",
    "train_features_list = train_numeric_inputs + train_string_inputs\n",
    "# Create your vector assembler object\n",
    "train_assembler = VectorAssembler(inputCols=train_features_list,outputCol='features')\n",
    "# And call on the vector assembler to transform your dataframe\n",
    "train_output = train_assembler.transform(train_indexed).select('features','label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we correct for negative values that may have been found above, \n",
    "# We need to vectorize our df\n",
    "test_features_list = test_numeric_inputs + test_string_inputs\n",
    "# Create your vector assembler object\n",
    "test_assembler = VectorAssembler(inputCols=test_features_list,outputCol='features')\n",
    "# And call on the vector assembler to transform your dataframe\n",
    "test_output = test_assembler.transform(test_indexed).select('features','label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the mix max scaler object \n",
    "train_scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",min=0,max=1000)\n",
    "print(\"Features scaled to range: [%f, %f]\" % (train_scaler.getMin(), train_scaler.getMax()))\n",
    "\n",
    "# Compute summary statistics and generate MinMaxScalerModel\n",
    "trainScalerModel = train_scaler.fit(train_output)\n",
    "\n",
    "# rescale each feature to range [min, max].\n",
    "train_scaled_data = trainScalerModel.transform(train_output)\n",
    "train_final_data = train_scaled_data.select('label','scaledFeatures')\n",
    "# Rename to default value\n",
    "train_final_data = train_final_data.withColumnRenamed(\"scaledFeatures\",\"features\")\n",
    "train_final_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the mix max scaler object \n",
    "test_scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",min=0,max=1000)\n",
    "print(\"Features scaled to range: [%f, %f]\" % (test_scaler.getMin(), test_scaler.getMax()))\n",
    "\n",
    "# Compute summary statistics and generate MinMaxScalerModel\n",
    "testScalerModel = test_scaler.fit(test_output)\n",
    "\n",
    "# rescale each feature to range [min, max].\n",
    "test_scaled_data = testScalerModel.transform(test_output)\n",
    "test_final_data = test_scaled_data.select('label','scaledFeatures')\n",
    "# Rename to default value\n",
    "test_final_data = test_final_data.withColumnRenamed(\"scaledFeatures\",\"features\")\n",
    "test_final_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MC_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\") # redictionCol=\"prediction\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "classifier = RandomForestClassifier(labelCol='label',featuresCol='features',maxDepth=10,numTrees=10,maxBins=10)\n",
    "\n",
    "fitModel = classifier.fit(train_final_data)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\" \")\n",
    "\n",
    "predictions = fitModel.transform(test_final_data)\n",
    "\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(\" \")\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "predictionLabels = predictions.select('prediction', 'label')\n",
    "metrics = MulticlassMetrics(predictionLabels.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = metrics.weightedPrecision\n",
    "recall = metrics.weightedRecall\n",
    "f_Measure = metrics.weightedFMeasure()\n",
    "true_positive_rate = metrics.weightedTruePositiveRate\n",
    "false_positive_rate = metrics.weightedFalsePositiveRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"f_Measure: \", f_Measure)\n",
    "print(\"true_positive_rate: \", true_positive_rate)\n",
    "print(\"false_positive_rate: \", false_positive_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
